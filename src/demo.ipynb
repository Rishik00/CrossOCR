{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import json\n",
    "import numpy as np\n",
    "from typing import List, Dict\n",
    "\n",
    "# Assuming these imports work in your environment\n",
    "from llms.vectorstore import FAISSEmbeddingsSearch\n",
    "from ocr.paddle_ocr import PaddleOCRutil\n",
    "from vlm.clip import CLiP\n",
    "\n",
    "def numpy_to_python(obj):\n",
    "    if isinstance(obj, np.integer):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, np.floating):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    return obj\n",
    "\n",
    "def process_image(image, faiss_prompt, clip_prompts):\n",
    "    text_prompts = {\n",
    "        'FAISSPrompt': [faiss_prompt],\n",
    "        'CliPPrompts': clip_prompts.split(','),\n",
    "    }\n",
    "\n",
    "    final_json_output = {\n",
    "        'text_score': None,\n",
    "        'image_score': None,\n",
    "    }\n",
    "\n",
    "    # OCR processing\n",
    "    ocr = PaddleOCRutil(image)\n",
    "    ocr_results, _ = ocr.parse_ocr_results()\n",
    "    \n",
    "    # CLIP processing\n",
    "    vlm = CLiP()\n",
    "    clip_res = vlm.inference(image, text_prompts['CliPPrompts'])\n",
    "    \n",
    "    clip_output = 'CLIP Matches:\\n'\n",
    "    for prompt, score in clip_res:\n",
    "        clip_output += f\"{prompt}: {numpy_to_python(score):.4f}\\n\"\n",
    "    \n",
    "    final_json_output['image_score'] = numpy_to_python(clip_res[0][1]) if clip_res else None\n",
    "\n",
    "    # FAISS processing\n",
    "    vems = FAISSEmbeddingsSearch()\n",
    "    corpus = list(ocr_results.keys())  \n",
    "    corpus_embeddings = vems.get_embeddings(corpus)\n",
    "    vems.create_faiss_index(corpus_embeddings)\n",
    "\n",
    "    query = text_prompts['FAISSPrompt'][0]\n",
    "    dist, ind = vems.get_query_result(query, k=1)\n",
    "\n",
    "    faiss_output = 'FAISS Results:\\n'\n",
    "    for i, idx in enumerate(ind[0]):\n",
    "        faiss_output += f\"Index: {idx}, Text: {corpus[idx]}, Distance: {numpy_to_python(dist[0][i])}\\n\"\n",
    "    \n",
    "    final_json_output['text_score'] = numpy_to_python(dist[0][0]) if len(dist) > 0 and len(dist[0]) > 0 else None\n",
    "\n",
    "    # Save FAISS index\n",
    "    vems.save_index(\"faiss_index.bin\")\n",
    "\n",
    "    final_output = json.dumps(final_json_output, indent=2, default=numpy_to_python)\n",
    "\n",
    "    return clip_output, faiss_output, final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## STarting a gradio interface\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=process_image,\n",
    "    inputs=[\n",
    "        gr.Image(type=\"filepath\", label=\"Upload Image\"),\n",
    "        gr.Textbox(lines=1, label=\"FAISS Prompt\"),\n",
    "        gr.Textbox(lines=2, label=\"CLIP Prompts (comma-separated)\")\n",
    "    ],\n",
    "    outputs=[\n",
    "        gr.Textbox(label=\"CLIP Results\"),\n",
    "        gr.Textbox(label=\"FAISS Results\"),\n",
    "        gr.JSON(label=\"Final Output\")\n",
    "    ],\n",
    "    title=\"IIT Roorkee Assignment Demo\",\n",
    "    description=\"Upload an image\"\n",
    ")\n",
    "\n",
    "iface.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
